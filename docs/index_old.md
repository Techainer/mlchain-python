<p align="center">
  <a href="https://mlchain.ml" target="_blank">
    <img src="https://i.imgur.com/oAMint7l.png" target="_blank" />
  </a><br>
  Deploy AI model at scale! <br>
  <a href="https://mlchain.ml/documentation/python/getting-started/" target="_blank">
    <strong> Explore the docs » </strong>
  </a> <br>
  <a href="https://mlchain.ml" target="_blank"> Our Website </a>
    ·
  <a href="https://github.com/techainer/examples-python" target="_blank"> Examples in Python </a>
</p>

# Mlchain Library for Python

[Mlchain](https://mlchain.ml) helps AI developers to easily run, deploy and monitor AI models and Workflows without needing software engineering experience.

This Mlchain Python library lets you launch models and do many tasks with Mlchain Platform. 

[Learn more](/getstarted/core_concepts.md)

### Seamless AI App Deployment

MLChain support you in building your own web-based AI application, where everything is pre-designed 
for your comfort. You will be able to test your app without cumbersome software engineering work that takes 
longer than training the data itself. 

Try our tutorial on [Model Deployment](/Model Deployment/tutorial.md).

### Sharing between clients

MLChain Client allows you to also share your AI model's output with regard to developer's specific input. 
This uses model that is directly hosted by your web-based app, so there is no need for rebuilding or 
making cumbersome APIs.

Try our tutorial on [Client Sharing](/Client/general.md).

### Workflow

Workflow is an independent function of MLChain that allows you to process your function 
in a <b> parallel </b> or a <b> pipeline </b> manner. This uses multi thread processing without
the need of complex DevOps programming, allowing your app to run multiple tasks 20 - 50 times faster than traditional approach.

Learn more about [Workflow](/workflow/general.md)
